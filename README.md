# E-commerce Product Categorization

## Project Description
This project aims to develop a machine learning model using Long Short-Term Memory (LSTM) to categorize unseen products into four categories: "Electronics", "Household", "Books" and "Clothing & Accessories". Leveraging TensorFlow and text classification techniques, the model achieves high accuracy and reliability, meeting the objective of an accuracy above 85% and an F1 score exceeding 0.7.

## Project Highlights
- Text Classification: Automatically categorizes product descriptions into predefined categories.
- LSTM Architecture: Employs LSTM for sequence modeling and feature extraction.
- Data Handling: Efficient preprocessing, tokenization and padding for optimal text representation.
- Performance Metrics: Evaluates accuracy, precision, recall and F1 score for robust assessment.
- Model Deployment: Saves trained models and tokenizer for future predictions.
- Visualization: Uses TensorBoard to monitor training progress and model performance.

## Challenges and Solutions
### Challenges
1) Data Preprocessing: Managing missing values, duplicates, tokenization, and padding.
2) Model Selection: Choosing an appropriate architecture for text classification.
3) Performance Optimization: Ensuring generalization and avoiding overfitting.

### Solutions
1) Utilized pandas for data cleaning and preprocessing.
2) Implemented TensorFlow Keras for model creation and training.
3) Applied scikit-learn metrics for evaluation and ensured a balanced dataset using augmentation techniques.

## Future Enhancements
1) Handling Imbalanced Datasets: Incorporating SMOTE or other techniques for class balance.
2) Hyperparameter Tuning: Experimenting with advanced tuning methods for improved results.
3) Multilingual Support: Expanding the model for multiple languages to increase versatility.

## File Structure
- ecommerceDataset.csv: Dataset with product descriptions and labels.
- farah-capstone2-ecommerce.ipynb: Main Python notebook containing project code.
- saved_models: Directory to store the trained model (model.h5).
- tokenizer.pkl: Pickled tokenizer object for future use.

## Setup and Dependencies
### Installation:
Install the required dependencies using the following commands:
```shell
pip install tensorflow==2.12.0  
pip install numpy==1.24.2  
pip install matplotlib==3.7.1  
pip install pandas==1.5.3  
pip install scikit-learn==1.2.2
```

### Getting started:
#### 1. Clone the repository to your local machine using the following command:
```shell
git clone https://github.com/farah2p/farah-capstone2-ecommerce-text.git
```
#### 2. Change to the project directory:
```shell
cd product-categorization
```
#### 3. Place the ecommerceDataset.csv in the project directory.

### How To Run:
#### 1. Open the Jupyter Notebook or Python script:
```shell
python farah-capstone2-ecommerce.ipynb  
```
#### 2. Perform the following:
- Data preprocessing.
- Train and evaluate the LSTM model.
- Save the model and tokenizer.
- Visualize results using TensorBoard:
```shell
tensorboard --logdir tensorboard_logs/capstone2  
```
Access TensorBoard in your browser using the provided URL.

## Results
The model achieved the following metrics:
- Training Loss: 0.0905
- Training Accuracy: 97.65%
- Validation Loss: 0.2122
- Validation Accuracy: 95.18%
- F1 Score: 0.952

## Evaluation
- Training Performance: Demonstrated a low loss and high accuracy, ensuring strong learning on the training data.
- Validation Performance: The model exhibited excellent generalization with high validation accuracy and minimal overfitting.
- F1 Score: A score of 0.952 highlights the model's balance between precision and recall, confirming its efficacy in categorizing products accurately.

The LSTM-based model surpassed the project's criteria, achieving over 85% accuracy and an F1 score above 0.7. It offers a reliable and scalable solution for automated product categorization, benefiting businesses in streamlining operations and improving customer experience.

Below are some sample visualizations generated by the project:

- Model performance:

![Model Performance](farah-model-performance.png)

- Model Architecture:

![Model Architecture](farah-model-summary.png)

- Tensorboard Accuracy:

![Tensorboard Accuracy](farah-accuracy-tensorboard.png)

- Tensorboard Loss:

![Tensorboard Loss](farah-loss-tensorboard.png)

## Credits
The dataset used in this project is sourced from Kaggle:
https://www.kaggle.com/datasets/saurabhshahane/ecommerce-text-classification

## Contributing
Contributions to this project are welcome. If you find any issues or have suggestions for improvement, please open an issue or submit a pull request on the GitHub repository.
